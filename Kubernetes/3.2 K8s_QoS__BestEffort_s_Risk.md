# 3.2 : QoS Class â€“ **BestEffort**

https://drive.google.com/file/d/1uQarejDCpGhAfyNhvSyw4CmMIgDq2VyW/view?usp=sharing

### ğŸ” YAML Breakdown

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nnappone
  namespace: learning
  labels:
    app: nnappone
spec:
  containers:
    - name: networknuts-app
      image: nginx
# âŒ NO `resources` block!

```

> ğŸ”´ Key Observation:
> 
> 
> There is **no `resources` section** â†’ **no `requests`**, **no `limits`** for CPU or memory.
> 

---

### ğŸ“Œ What Is "BestEffort" QoS?

Kubernetes automatically assigns a **Quality of Service (QoS) class** to every Pod based on its **resource configuration**.

| QoS Class | Condition | Priority | Eviction Risk |
| --- | --- | --- | --- |
| **Guaranteed** | `requests == limits` for **all** containers & **all** resources (CPU + memory) | ğŸ” Highest | Never evicted due to resource pressure (if node has capacity) |
| **Burstable** | Some resources have `requests` â‰  `limits`, or only `requests`/`limits` set for **some** resources | ğŸŸ¡ Medium | Evicted **after** BestEffort, **before** Guaranteed |
| **BestEffort** | âŒ **No `requests` or `limits`** for **any** container | ğŸ”» Lowest | **First to be evicted** under memory pressure! |

> ğŸ’¡ BestEffort = "Use whatever is free â€” but we make no promises."
> 

---

### âš ï¸ Why Avoid BestEffort in Production?

- **Unpredictable performance**: Your app may get starved if other Pods consume resources.
- **First to die**: During **Node Memory Pressure**, kubelet **kills BestEffort Pods first**.
- **No scheduling guarantees**: Scheduler doesnâ€™t reserve resources for it.

> âœ… Only acceptable for:
> 
> - Temporary debug Pods
> - Labs/learning
> - Truly stateless, non-critical workloads

---

### ğŸ§ª Lab: Deploy BestEffort Pod & Verify QoS

### ğŸ”§ Steps

```bash
# 1. Create namespace
kubectl create namespace learning

# 2. Apply the Pod
kubectl apply -f pod-simple-qos-besteffort.yml

# 3. Check Pod status
kubectl get pods -n learning

# 4. Describe Pod â†’ look for "QoS Class"
kubectl describe pod nnappone -n learning | grep "QoS Class"

# âœ… Expected output:
# QoS Class:       BestEffort

# 5. (Optional) View full resource info in JSON
kubectl get pod nnappone -n learning -o jsonpath='{.status.qosClass}{"\\n"}'

# 6. Clean up
kubectl delete pod nnappone -n learning
kubectl delete namespace learning

```

---

### ğŸ” Compare with Other QoS Classes (Preview)

| Pod Type | `resources` Config | QoS Class |
| --- | --- | --- |
| This Pod | âŒ None | **BestEffort** |
| `pod-with-resource-limits.yml` | `requests: 500m/128Mi`, `limits: 1000m/256Mi` | **Burstable** |
| `guaranteed-pod.yaml` (coming next) | `requests: 500m/128Mi`, `limits: 500m/128Mi` | **Guaranteed** |

> ğŸ¯ Rule for Guaranteed:
> 
> 
> Every container must have **equal `requests` and `limits`** for **both CPU and memory**.
> 

---

### â“ Common Questions

**Q: Can a Pod have mixed QoS across containers?**

A: **No.** The **lowest** QoS among containers determines the **Podâ€™s QoS**.

Example: 1 container = Guaranteed, 1 = BestEffort â†’ **entire Pod = BestEffort**.

**Q: Does BestEffort mean no CPU/memory usage?**

A: **No!** It can use **all available resources** â€” but gets **no protection** when resources are scarce.

**Q: How does kubelet decide eviction order?**

A:

1. **BestEffort**
2. **Burstable** (sorted by how much they exceed requests)
3. **Guaranteed**

---

### â¡ï¸ Summary

âœ… **BestEffort** = **no resource requests/limits** defined.

âš ï¸ **Lowest priority** â€” first to be **killed under memory pressure**.

ğŸ” Verify with: `kubectl describe pod <name> | grep "QoS Class"`

ğŸš« **Avoid in production** â€” always set at least **`requests`**.