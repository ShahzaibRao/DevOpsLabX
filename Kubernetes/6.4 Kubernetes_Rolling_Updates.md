# 6.4 : Advanced Deployment Strategies

https://drive.google.com/file/d/1qKdVhVyAGGDDu2tDHUG0w-p19PFrTH_4/view?usp=sharing

### ğŸ” YAML Breakdown

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-deploy
  annotations:
    kubernetes.io/change-cause: "changing version to new"
spec:
  revisionHistoryLimit: 5        # â† Keep last 5 ReplicaSets
  replicas: 10                   # â† Run 10 Pods
  minReadySeconds: 10            # â† Wait 10s after Pod is ready before marking update successful
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1        # â† Max 1 Pod unavailable during update
      maxSurge: 1              # â† Max 1 extra Pod during update
  selector:
    matchLabels:
      app: hello-world
  template:
    metadata:
      labels:
        app: hello-world
    spec:
      containers:
      - name: hello-pod
        image: lovelearnlinux/webserver:v1
        readinessProbe:          # â† Critical for zero-downtime
          exec: { command: ["cat", "/var/www/html/index.html"] }
          initialDelaySeconds: 10
          periodSeconds: 10
        livenessProbe:           # â† Restart if app crashes
          exec: { command: ["cat", "/var/www/html/index.html"] }
          failureThreshold: 6    # â† Allow 6 failures before restart
        resources:
          requests:
            cpu: "50m"
            memory: "100Mi"
          limits:
            cpu: "100m"
            memory: "128Mi"

```

---

### ğŸ“Œ Key Strategy Parameters Explained

| Parameter | Meaning | Your Value | Effect |
| --- | --- | --- | --- |
| **`maxUnavailable: 1`** | Max Pods **unavailable** during update | `1` | Always keep **9/10 Pods serving traffic** |
| **`maxSurge: 1`** | Max **extra Pods** during update | `1` | Temporarily run **11 Pods** (10 old + 1 new â†’ then scale down) |
| **`minReadySeconds: 10`** | Wait after Pod is ready | `10s` | Ensures Pod is **stable** before proceeding |

> ğŸ¯ Rolling Update Flow (10 replicas):
> 
> 1. Start with 10 v1 Pods
> 2. Create **1 v2 Pod** â†’ total = 11 (`maxSurge: 1`)
> 3. Wait for v2 Pod to be **ready + 10s** (`minReadySeconds`)
> 4. Delete **1 v1 Pod** â†’ total = 10 (`maxUnavailable: 1` â†’ 9 available during delete)
> 5. Repeat until all 10 are v2

> âœ… Result: Zero downtime, controlled pace, minimal resource overhead
> 

---

### ğŸ§ª k3s Lab: Observe Rolling Update Strategy

### ğŸ”§ Step 1: Deploy v1

```bash
# Apply Deployment
kubectl apply -f deployment-with-strategy.yaml

# Wait for all Pods ready
kubectl get pods -l app=hello-world -w

```

### ğŸ”§ Step 2: Trigger Update to v2

```bash
# Update image to v2
kubectl set image deployment/hello-deploy hello-pod=lovelearnlinux/webserver:v2 \\
  --record  # â† Records change-cause automatically

# OR use annotate (as in your comment)
kubectl annotate deployment hello-deploy \\
  kubernetes.io/change-cause="image changed to v2" --overwrite

```

### ğŸ”§ Step 3: Watch the Rolling Update

```bash
# Watch Pods during update
kubectl get pods -l app=hello-world -w

# âœ… Expected behavior:
# - Total Pods fluctuates between 10 and 11
# - At least 9 Pods always in "Running" state
# - New Pods have image v2, old have v1

# Check rollout status
kubectl rollout status deployment hello-deploy

```

### ğŸ”§ Step 4: Inspect History & Revisions

```bash
# View rollout history
kubectl rollout history deployment hello-deploy

# View details of a revision
kubectl rollout history deployment hello-deploy --revision=2

# Rollback if needed
kubectl rollout undo deployment hello-deploy

```

> ğŸ” revisionHistoryLimit: 5 means only last 5 ReplicaSets are kept â†’ saves etcd space.
> 

---

### ğŸ’¡ Real-World Strategy Tuning

| Scenario | `maxUnavailable` | `maxSurge` | Why |
| --- | --- | --- | --- |
| **Stateless web app** | `25%` (default) | `25%` | Fast updates, tolerate brief downtime |
| **Payment processing** | `0` | `1` | **Zero downtime** critical |
| **Batch processor** | `100%` | `0` | Can afford downtime, minimize resource use |
| **GPU workload** | `0` | `0` | Canâ€™t afford extra GPU cost |

> âœ… Your settings (maxUnavailable: 1, maxSurge: 1) are ideal for critical apps with 10 replicas.
> 

---

### ğŸ› ï¸ Pro Tips for k3s

1. **Always set `minReadySeconds`** â†’ prevents "flapping" updates.
2. **Use `-record` with `kubectl set image`** â†’ auto-populates `change-cause`.
3. **Monitor during rollout**:
    
    ```bash
    kubectl get rs -l app=hello-world  # Watch old/new ReplicaSets
    
    ```
    
4. **Pause if something looks wrong**:
    
    ```bash
    kubectl rollout pause deployment hello-deploy
    # Investigate...
    kubectl rollout resume deployment hello-deploy
    
    ```
    

---

### â“ Common Questions

**Q: What if a new Pod fails readiness probe?**

A: Update **pauses**! Kubernetes wonâ€™t kill old Pods until new ones are ready.

**Q: Can I change strategy mid-rollout?**

A: âœ… Yes! Edit Deployment YAML â†’ `kubectl apply` â†’ new strategy applies to **remaining updates**.

**Q: Whatâ€™s the difference between `failureThreshold` in liveness vs readiness?**

A:

- **Liveness**: After `failureThreshold` failures â†’ **restart container**
- **Readiness**: After `failureThreshold` failures â†’ **remove from Service endpoints** (no restart)

**Q: Does `maxSurge: 1` mean +1 total or +1 per update step?**

A: **+1 total** â†’ Kubernetes ensures **total Pods â‰¤ replicas + maxSurge**

---

### â¡ï¸ Summary

âœ… **`maxUnavailable`** = max Pods **down** during update

âœ… **`maxSurge`** = max **extra Pods** during update

âœ… **`minReadySeconds`** = stability buffer after Pod is ready

âœ… **Revision history** enables safe rollbacks

ğŸ” In k3s: Works identically â€” perfect for testing strategies