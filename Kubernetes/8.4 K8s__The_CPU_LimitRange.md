# 8.4: CPU-Only LimitRange

https://drive.google.com/file/d/1o2eUiyAj-6naAc3IJXsSbSnRqvgzWz8H/view?usp=sharing

### ğŸ” YAML Breakdown

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-limit-range
  namespace: learning
spec:
  limits:
  - default:              # â† CPU limit if not specified
      cpu: 1              # = 1000m (1 full core)
    defaultRequest:       # â† CPU request if not specified
      cpu: 0.4            # = 400m (0.4 cores)
    type: Container

```

> ğŸ”‘ Key Insight:
> 
> 
> This LimitRange **only manages CPU** â€” memory is **not constrained** (Pods can use any memory unless restricted elsewhere).
> 

> ğŸ’¡ Why CPU-only?
> 
> - **CPU is compressible**: Throttled when exceeded (no crash)
> - **Memory is incompressible**: OOMKilled when exceeded
> â†’ Teams often **treat them differently**

---

### ğŸ“Œ How CPU Units Work

| Format | Meaning | Equivalent |
| --- | --- | --- |
| `1` | 1 CPU core | `1000m` |
| `0.4` | 0.4 CPU cores | `400m` |
| `500m` | 500 milliCPU | `0.5` |

> âœ… Best Practice:
> 
> 
> Use **`m` (millicores)** for clarity:
> 
> ```yaml
> defaultRequest:
>   cpu: "400m"
> default:
>   cpu: "1000m"
> 
> ```
> 

> âš ï¸ Your YAML uses decimals (0.4, 1) â†’ valid, but m is more explicit.
> 

---

### ğŸ§ª k3s Lab: Test CPU-Only LimitRange

### ğŸ”§ Step 1: Create Namespace & Apply LimitRange

```bash
# Create namespace
kubectl create namespace learning

# Apply LimitRange
kubectl apply -f namespace-cpu-limitrange.yaml

# Verify
kubectl describe limitrange cpu-limit-range -n learning
# Type       Resource  Min  Max  Default Request  Default Limit
# Container  cpu       -    -    400m               1

```

### ğŸ”§ Step 2: Deploy Pod with NO CPU Resources

```yaml
# pod-no-cpu.yaml
apiVersion: v1
kind: Pod
meta
  name: no-cpu-pod
  namespace: learning
spec:
  containers:
  - name: nginx
    image: nginx

```

```bash
kubectl apply -f pod-no-cpu.yaml

# Check applied CPU resources
kubectl get pod no-cpu-pod -n learning -o jsonpath='{.spec.containers[0].resources}'
# âœ… Output:
# {"limits":{"cpu":"1"},"requests":{"cpu":"0.4"}}

```

> ğŸ” Result:
> 
> 
> LimitRange **auto-applied CPU defaults** â†’ Pod has **400m request, 1000m limit**
> 

### ğŸ”§ Step 3: Deploy Pod with Custom CPU (Within Implicit Max)

```yaml
# pod-custom-cpu.yaml
apiVersion: v1
kind: Pod
meta
  name: custom-cpu-pod
  namespace: learning
spec:
  containers:
  - name: nginx
    image: nginx
    resources:
      requests:
        cpu: "600m"
      limits:
        cpu: "1500m"   # > default limit, but no max defined â†’ allowed!

```

```bash
kubectl apply -f pod-custom-cpu.yaml
# âœ… Success! (No max defined â†’ no enforcement)

```

> âš ï¸ Critical Observation:
> 
> 
> Your LimitRange **does NOT define `max`** â†’ Pods can request **unlimited CPU**!
> 
> â†’ This is **risky in production** (use `max` to cap usage).
> 

### ğŸ”§ Step 4: Add `max` to Prevent Abuse (Recommended Fix)

```yaml
# Improved LimitRange (with max)
spec:
  limits:
  - default:
      cpu: "1000m"
    defaultRequest:
      cpu: "400m"
    max:                # â† ADD THIS!
      cpu: "2000m"      # Max 2 cores per container
    type: Container

```

### ğŸ”§ Step 5: Clean Up

```bash
kubectl delete pod --all -n learning
kubectl delete limitrange cpu-limit-range -n learning
kubectl delete namespace learning

```

---

### ğŸ’¡ Real-World CPU LimitRange Strategies

| Workload Type | `defaultRequest` | `default` | `max` | Why |
| --- | --- | --- | --- | --- |
| **Web Server** | 100m | 500m | 1000m | Handles traffic spikes |
| **Batch Job** | 500m | 1000m | 2000m | CPU-intensive, short-lived |
| **ML Inference** | 1000m | 2000m | 4000m | Needs consistent CPU |
| **Sandbox** | 50m | 100m | 500m | Prevents resource hogging |

> âœ… Best Practices:
> 
> - **Always set `max`** in production
> - Use **millicores (`m`)** for clarity
> - **Monitor CPU usage** (`kubectl top pods`) to tune defaults

---

### ğŸ†š CPU vs Memory LimitRange

| Aspect | **CPU LimitRange** | **Memory LimitRange** |
| --- | --- | --- |
| **Enforcement** | Throttling (no crash) | OOMKilled (crash) |
| **Default Strategy** | Lower request, higher limit (bursting) | Request â‰ˆ limit (no bursting) |
| **Units** | Cores or millicores (`1` or `1000m`) | Bytes (`Mi`, `Gi`) |
| **Risk of No Max** | High CPU usage â†’ node slowdown | High memory â†’ node OOM |

> ğŸ’¡ Your next file (namespace-memory-limitrange.yml) will cover memory-specific constraints.
> 

---

### â“ Common Questions

**Q: What if I mix CPU and memory in one LimitRange?**

A: âœ… **Yes!** (Like your earlier `limit-ranges.yaml`). Separating them is optional.

**Q: Does CPU limit affect scheduling?**

A: âŒ **No!** Only `requests.cpu` affects scheduling. `limits.cpu` affects **runtime throttling**.

**Q: Can I use fractional values like `0.1`?**

A: âœ… **Yes!** But `100m` is clearer than `0.1`.

**Q: Whatâ€™s the smallest CPU request?**

A: **1m** (0.001 core) â€” but **10m+ recommended** for scheduler accuracy.

---

### â¡ï¸ Summary

âœ… **CPU-only LimitRange** = control CPU defaults separately

âœ… **`defaultRequest`** = guaranteed CPU (for scheduling)

âœ… **`default`** = max CPU (for runtime throttling)

âš ï¸ **Always add `max`** to prevent abuse

ğŸ” In k3s: Test with **no-CPU Pod** â†’ see defaults applied

â¡ï¸ Next: **Memory-only LimitRange** (`namespace-memory-limitrange.yml`)